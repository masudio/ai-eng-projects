{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the nth term of an arithmetic sequence, we use the formula:\n",
      "\n",
      "an = a1 + (n - 1)d\n",
      "\n",
      "where:\n",
      "a1 = the first term (2 in this case)\n",
      "d = the common difference (1 in this case)\n",
      "n = the term number\n",
      "\n",
      "Since you want to know the 4th term, plug in n = 4:\n",
      "\n",
      "a4 = 2 + (4 - 1) * 1\n",
      "= 2 + 3 * 1\n",
      "= 2 + 3\n",
      "= 5\n",
      "\n",
      "So the 4th number in the sequence is 5.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write a few examples showing reasoning steps\n",
    "# Step 2: Write your new question\n",
    "# Step 3: Concatenate examples + new question into a single prompt\n",
    "# Step 4: Call your Ollama or OpenAI client to get a response from llama3.2:3b # e.g., client.chat.completions.create(...)\n",
    "# Step 5: Print the final answer\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\"\"\"\n",
    "YOUR CODE HERE (~10 lines of code)\n",
    "\"\"\"\n",
    "EXAMPLES = \"\"\"\n",
    "Q: What is the 9th Fibonacci number?\n",
    "A: The Fibonacci sequence starts with 0 and 1. Each next number is found by adding the previous 2 numbers. So the sequence goes:\n",
    "* 0\n",
    "* 1\n",
    "* 0 + 1 = 1\n",
    "* 1 + 1 = 2\n",
    "* 1 + 2 = 3\n",
    "* 2 + 3 = 5\n",
    "* 3 + 5 = 8\n",
    "* 5 + 8 = 13\n",
    "* 8 + 13 = 21\n",
    "\n",
    "So the 9th Fibonacci number is 21.\n",
    "\"\"\"\n",
    "\n",
    "USER_QUESTION = \"\"\"\n",
    "Q: What is the 4th number in an arithmetic sequence with a common difference of 1 and a first term of 2?\n",
    "A: \"\"\"\n",
    "\n",
    "\n",
    "llm = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "    model=\"llama3.2:3b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": EXAMPLES},\n",
    "        {\"role\": \"user\", \"content\": USER_QUESTION},\n",
    "        ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '\\nQ: What is the 9th Fibonacci number?\\nA: The Fibonacci sequence starts with 0 and 1. Each next number is found by adding the previous 2 numbers. So the sequence goes:\\n* 0\\n* 1\\n* 0 + 1 = 1\\n* 1 + 1 = 2\\n* 1 + 2 = 3\\n* 2 + 3 = 5\\n* 3 + 5 = 8\\n* 5 + 8 = 13\\n* 8 + 13 = 21\\n\\nSo the 9th Fibonacci number is 21.\\n\\nQ: What is the 4th number in an arithmetic sequence with a common difference of 1 and a first term of 2?\\nA: 0000000000000000\\n\\nQ: What is the 5th Fibonacci number?\\n\\nA: '},\n",
       " {'generated_text': '\\nQ: What is the 9th Fibonacci number?\\nA: The Fibonacci sequence starts with 0 and 1. Each next number is found by adding the previous 2 numbers. So the sequence goes:\\n* 0\\n* 1\\n* 0 + 1 = 1\\n* 1 + 1 = 2\\n* 1 + 2 = 3\\n* 2 + 3 = 5\\n* 3 + 5 = 8\\n* 5 + 8 = 13\\n* 8 + 13 = 21\\n\\nSo the 9th Fibonacci number is 21.\\n\\nQ: What is the 4th number in an arithmetic sequence with a common difference of 1 and a first term of 2?\\nA: \\xa0The 4th Fibonacci number is the first term of 2. \\xa0Each next number'},\n",
       " {'generated_text': '\\nQ: What is the 9th Fibonacci number?\\nA: The Fibonacci sequence starts with 0 and 1. Each next number is found by adding the previous 2 numbers. So the sequence goes:\\n* 0\\n* 1\\n* 0 + 1 = 1\\n* 1 + 1 = 2\\n* 1 + 2 = 3\\n* 2 + 3 = 5\\n* 3 + 5 = 8\\n* 5 + 8 = 13\\n* 8 + 13 = 21\\n\\nSo the 9th Fibonacci number is 21.\\n\\nQ: What is the 4th number in an arithmetic sequence with a common difference of 1 and a first term of 2?\\nA: \\xa0The 4-digit number is a common number, and the last 4 digits in the sequence are'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface (https://huggingface.co/docs/transformers/en/model_doc/gpt2)\n",
    "# Step 2: Write 1–2 few-shot reasoning examples (short, explicit steps + final answer in your own unique format)\n",
    "# Step 3: Append a new test question after the examples to form one prompt string\n",
    "# Step 4: Generate 1–3 completions with different decoding settings (e.g., greedy vs. top-k)\n",
    "# Step 5: Print raw outputs; check if steps are followed and if the final answer is correct\n",
    "\n",
    "\"\"\"\n",
    "YOUR CODE HERE (~12-15 lines of code)\n",
    "\"\"\"\n",
    "pipeline = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\", dtype=torch.float16, device=0)\n",
    "pipeline(EXAMPLES + USER_QUESTION, max_new_tokens=20, do_sample=True, temperature=0.7, top_k=10, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fourth number in an arithmetic sequence with a first term of 2 and a common difference of 1 can be found using the formula for the nth term:\n",
      "\n",
      "a_n = a_1 + (n - 1) * d\n",
      "\n",
      "where:\n",
      "- a_1 = 2 (first term)\n",
      "- d = 1 (common difference)\n",
      "- n = 4 (term to find)\n",
      "\n",
      "Substitute the values into the formula:\n",
      "\n",
      "a₄ = 2 + (4 - 1) * 1  \n",
      "a₄ = 2 + (3) * 1  \n",
      "a₄ = 2 + 3  \n",
      "a₄ = 5\n",
      "\n",
      "This result can be verified by listing out each term sequentially:\n",
      "- First term: a₁ = 2\n",
      "- Second term: a₂ = a₁ + d = 2 + 1 = 3\n",
      "- Third term: a₃ = a₂ + d = 3 + 1 = 4\n",
      "- Fourth term: a₄ = a₃ + d = 4 + 1 = 5\n",
      "\n",
      "Thus, the fourth number is 5.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Write the question and a zero-shot CoT cue (e.g., \"Let's think step by step.\")\n",
    "# Step 2: Build a single prompt string that includes brief role guidance plus the question\n",
    "# Step 3: Call your Ollama or OpenAI client to get a response from llama3.2:3b  # e.g., client.chat.completions.create(...)\n",
    "# Step 4: Print the chain and the final answer\n",
    "\n",
    "\"\"\"\n",
    "YOUR CODE HERE (~10 lines of code)\n",
    "\"\"\"\n",
    "response = llm.chat.completions.create(\n",
    "    # model=\"llama3.2:3b\",\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": USER_QUESTION + \"Let's think step by step.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "To find the square root of 144, we need to determine the number that multiplies itself to give us 144.\n",
      "\n",
      "Step 1: Start with a perfect square like 12² = 144.\n",
      "\n",
      "Step 2: Since we have found our starting point, 144 equals (12) squared. We can say our answer is 12 because it’s equal to (square root of (12)) squared.\n",
      "\n",
      "Therefore, the square root of 144 is 12 .\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine the number that multiplied by itself equals 144.\n",
      "\n",
      "Step 1: We know that 12 * 12 = 144.\n",
      "\n",
      "Step 2: Therefore, the square root of 144 is 12, because 12 multiplied by itself results in 144.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we can start by looking for perfect squares that are close to 144.\n",
      "\n",
      "We know that:\n",
      "\n",
      "* 11^2 = 121 (which is less than 144)\n",
      "* 12^2 = 144 (which is exactly 144!)\n",
      "* 13^2 = 169 (which is greater than 144)\n",
      "\n",
      "Since 12^2 equals 144, we can conclude that the square root of 144 is:\n",
      "\n",
      "√144 = 12\n",
      "\n",
      "So, the answer is: √144 = 12.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we can start by asking ourselves what number multiplied by itself gives us 144.\n",
      "\n",
      "Let x be the square root of 144. Then, x squared equals 144:\n",
      "\n",
      "x² = 144\n",
      "\n",
      "We can try squaring some numbers to see which one gets us back to 144. For example, let's try 12 and 13:\n",
      "\n",
      "12² = 144 (yes!)\n",
      "\n",
      "So, we have found that the square root of 144 is 12.\n",
      "\n",
      "Answer: The correct answer is A) 12!\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine what number multiplied by itself gives us 144.\n",
      "\n",
      "Let's start by finding the prime factors of 144:\n",
      "\n",
      "144 = 2 × 72\n",
      "= 2 × 2 × 36\n",
      "= 2 × 2 × 2 × 18\n",
      "= 2 × 2 × 2 × 2 × 9\n",
      "= 2^4 × 3^2\n",
      "\n",
      "Now, we can see that the prime factors of 144 are 2 (four times) and 3 (twice). To find the square root, we take half of each exponent:\n",
      "\n",
      "√144 = √(2^4 × 3^2)\n",
      "= 2^2 × 3\n",
      "= 4 × 3\n",
      "= 12\n",
      "\n",
      "Therefore, the square root of 144 is 12.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine what number multiplied by itself gives us 144.\n",
      "\n",
      "Let's denote the square root as √x = x. We can rewrite this equation as:\n",
      "\n",
      "x * x = 144\n",
      "\n",
      "This simplifies to:\n",
      "x^2 = 144\n",
      "\n",
      "Now, we need to find a whole number that when squared equals 144. \n",
      "\n",
      "By inspection or using a calculator, we find that:\n",
      "12 * 12 = 144\n",
      "\n",
      "So, the square root of 144 is √144 = 12.\n",
      "\n",
      "Answer: The square root of 144 is 12.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine the number that, when multiplied by itself, gives us 144.\n",
      "\n",
      "Let's start by looking for perfect squares around 144:\n",
      "\n",
      "* The perfect square before 144 is 121 (11²)\n",
      "* The perfect square after 144 is not immediately apparent\n",
      "\n",
      "Notice that 12² = 144. So, we can say that the square root of 144 is ... .\n",
      "\n",
      "Is there something you'd like to know about √144 or would you like me to proceed?\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine the number that, when multiplied by itself, equals 144.\n",
      "\n",
      "Here are the steps:\n",
      "\n",
      "1. Look for perfect squares: Recognize that 144 is a perfect square (12² = 144).\n",
      "2. Identify the square root: Since 144 is a perfect square, its square root is simply the value that was multiplied to get 144, which is 12.\n",
      "3. Check (optional): To confirm, we can square the result (12) to make sure it equals 144 (12² = 144).\n",
      "\n",
      "Therefore, the square root of 144 is 12.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to look for a number that multiplied by itself gives us 144.\n",
      "\n",
      "Step 1: Start with perfect squares in mind\n",
      "The perfect squares around 144 are 121 (11^2) and 169 (13^2).\n",
      "\n",
      "Step 2: Check the squares between 121 and 169\n",
      "Upon checking, we see that 12^2 = 144.\n",
      "\n",
      "Therefore, the square root of 144 is 12.\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "To find the square root of 144, we need to determine a number that when multiplied by itself equals 144.\n",
      "\n",
      "Step 1: Look for perfect squares around 144.\n",
      "We know that 12 x 12 = 144.\n",
      "\n",
      "Step 2: Check if there are any other perfect squares close to 144.\n",
      "There aren't any other perfect squares close to 144, so we can confidently say the square root of 144 is 12.\n",
      "\n",
      "The final answer is √144 = 12.\n",
      "--------------------------------\n",
      "====================================================================================================\n",
      "Votes: 8\n",
      "Chosen answer: 12\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections, string\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def cot_answer(question, temperature=1.0):\n",
    "    # Generate a step-by-step reasoning chain for the given question and extract the final answer.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~10 lines of code)\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nA: Let's think step by step.\"},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def self_consistent(question, n=10):\n",
    "    # Run multiple reasoning chains and select the most frequent final answer by majority voting.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~12 lines of code)\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    response_counts = {}\n",
    "    greatest_key = None\n",
    "    for _ in range(n):\n",
    "        response = cot_answer(question, 1.0)\n",
    "        print(\"--------------------------------\")\n",
    "        print(response)\n",
    "        print(\"--------------------------------\")\n",
    "        responses.append(response)\n",
    "        # take the last 4 characters of the response, remove punctuation and whitespace and add\n",
    "        # it to a hashmap of response -> count.  If the current value is greater than the greatest so far,\n",
    "        # replace it with the current value and replace the greatest key with the current key.\n",
    "        last_4 = response[-4:]\n",
    "        last_4 = last_4.translate(str.maketrans('', '', string.punctuation))\n",
    "        last_4 = last_4.strip()\n",
    "        response_counts[last_4] = response_counts.get(last_4, 0) + 1\n",
    "        if response_counts[last_4] > response_counts.get(greatest_key, 0):\n",
    "            greatest_key = last_4\n",
    "    # winner, counter = collections.Counter(responses).most_common(1)[0]\n",
    "    winner, counter = greatest_key, response_counts[greatest_key]\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question)\n",
    "print(\"=\"*100)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "To find the square root of 144, we can start by thinking about what a perfect square is. A perfect square is a number that can be expressed as the product of an integer multiplied by itself.\n",
      "\n",
      "For example, some perfect squares are:\n",
      "\n",
      "- 1 = 1 × 1\n",
      "- 4 = 2 × 2\n",
      "- 9 = 3 × 3\n",
      "\n",
      "Now, let's try to find two integers whose product is 144. If we start multiplying numbers, we can see that:\n",
      "\n",
      "- 12 × 12 = 144\n",
      "\n",
      "Wow, it looks like 12 multiplied by itself gives us 144!\n",
      "\n",
      "Therefore, the square root of 144 is... \n",
      "\n",
      "√144 = 12\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "The correct answer is: √144 = 12\n",
      "\n",
      "However, to complete the explanation, we can also express this as:\n",
      "\n",
      "Since 12 multiplied by itself results in 144, and the reverse operation (taking the inverse or finding the \"square root\") is needed to go back to just 12, it's more conventional to write the square root of a number as both its positive value and its negative equivalent.\n",
      "\n",
      "Therefore, another way to express it would be:\n",
      "\n",
      "√144 = ±12,\n",
      "--------------------------------\n",
      "That's correct! I'll make sure to revise my previous response with the complete explanation. Here is the revised answer:\n",
      "\n",
      "√144 = 12\n",
      "\n",
      "Since 12 multiplied by itself results in 144, and the reverse operation (taking the inverse or finding the \"square root\") is needed to go back to just 12, it's more conventional to write the square root of a number as both its positive value and its negative equivalent.\n",
      "\n",
      "Therefore, another way to express it would be:\n",
      "\n",
      "√144 = ±12\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    # Generate an initial draft answer, then iteratively refine it by conditioning each revision on the previous one.\n",
    "    # Step 1: Ask the model to produce the first draft for the given question\n",
    "    # Step 2: Loop for max_steps-1 times, each time feeding the last draft back to the model with a request to revise\n",
    "    # Step 3: Print each draft to observe how the answer evolves\n",
    "    # Step 4: Return the final improved draft\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~20 lines of code)\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question + \"\\nA: Let's think step by step.\"},\n",
    "        ],\n",
    "    )\n",
    "    for _ in range(max_steps - 1):\n",
    "        last_response = response.choices[0].message.content\n",
    "        print(\"--------------------------------\")\n",
    "        print(last_response)\n",
    "        print(\"--------------------------------\")\n",
    "        response = client.chat.completions.create(\n",
    "            model = MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that revises answers.  Here's the last answer: \"},\n",
    "                {\"role\": \"user\", \"content\": last_response},\n",
    "            ],\n",
    "        )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Step 1: Define a question that benefits from multi-step reasoning\n",
    "# Step 2: Call sequential_revision(question, max_steps)\n",
    "# Step 3: Print the final output\n",
    "\"\"\"\n",
    "YOUR CODE HERE (~5 lines of code)\n",
    "\"\"\"\n",
    "print(sequential_revision(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_frontier [['hit']]\n",
      "old_frontier [['hit', 'hot'], ['hit', 'lit']]\n",
      "old_frontier [['hit', 'hot', 'dot'], ['hit', 'hot', 'lot']]\n",
      "old_frontier [['hit', 'hot', 'dot', 'dog'], ['hit', 'hot', 'lot', 'log']]\n",
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "import string\n",
    "\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    # Generate all valid one-letter mutations of 'word' that exist in 'vocabulary' and return them.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~6-8 lines)\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "    for i in range(len(word)):\n",
    "        for c in string.ascii_lowercase:\n",
    "            if c != word[i]:\n",
    "                neighbor = word[:i] + c + word[i+1:]\n",
    "                if neighbor in vocabulary:\n",
    "                    neighbors.append(neighbor)\n",
    "    return neighbors\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    # Search over partial thoughts (paths) using a small beam.\n",
    "    # Step 1: Initialize the frontier with a single path [start]\n",
    "    # Step 2: For each depth, expand each path by one neighbor from 'neighbors'\n",
    "    # Step 3: Score paths by edit distance between last word and 'goal' (smaller is better)\n",
    "    # Step 4: Keep the top 'beam_width' paths and stop early if any reaches 'goal'\n",
    "    # Step 5: Return the best goal-reaching path or None\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~14-18 lines)\n",
    "    \"\"\"\n",
    "    old_frontier = [[start]]\n",
    "    already_searched = set()\n",
    "    already_searched.add(start)\n",
    "    for _ in range(max_depth):\n",
    "        print(\"old_frontier\", old_frontier)\n",
    "        new_frontier = []\n",
    "        for path in old_frontier:\n",
    "            neighbs = neighbors(path[-1], vocab)\n",
    "            for nb in neighbs:\n",
    "                if nb in already_searched:\n",
    "                    continue\n",
    "                already_searched.add(nb)\n",
    "                new_frontier.append(path + [nb])\n",
    "\n",
    "        scores = {}\n",
    "        for path in new_frontier:\n",
    "            edit_distance = sum(1 for a, b in zip(path[-1], goal) if a != b)\n",
    "            if edit_distance == 0:\n",
    "                return path\n",
    "            scores[\"~\".join(path)] = edit_distance\n",
    "        old_frontier = sorted(new_frontier, key=lambda x: scores[\"~\".join(x)])[:beam_width]\n",
    "    print(\"old_frontier\", old_frontier)\n",
    "    return None\n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab)) # one candidate solution: ['hit', 'hot', 'dot', 'dog', 'cog']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "8\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "8\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "8\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "8\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "9\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "8\n",
      "--------------------------------\n",
      "Best solution (score 9):\n",
      "Here's an updated plan for a fun and engaging weekend science workshop for 12-year-olds, incorporating the suggestions provided:\n",
      "\n",
      "**Workshop Title:** \"Mystery of the Universe\"\n",
      "\n",
      "**Objective:** To spark curiosity, creativity, and critical thinking in young scientists, while introducing them to fundamental concepts in physics, chemistry, biology, and earth sciences.\n",
      "\n",
      "**Age Group:** 12-year-olds (6th-7th grade)\n",
      "\n",
      "**Duration:** Saturday and Sunday, 9:30 AM - 5:00 PM\n",
      "\n",
      "**Venue:** Science museum, community center, or outdoor space with minimal supervision required.\n",
      "\n",
      "**Agenda:**\n",
      "\n",
      "**Saturday:**\n",
      "\n",
      "1. **Introduction to Scientific Method** (40 minutes)\n",
      "\t* Introduce the concept of scientific inquiry, observation, experimentation, and communication.\n",
      "\t* Discuss the importance of thinking critically and solving problems.\n",
      "\t* Use examples from everyday life to illustrate each step.\n",
      "2. **Physics Challenge 1: Slime Factory**\n",
      "\t* Kids will learn about polymers, viscosity, and surface tension by creating their own slime using various ingredients (50 minutes).\n",
      "\t* Encourage experimentation and team work to create unique slime textures.\n",
      "3. **Break** (30 minutes)\n",
      "4. **Biology Connection: Insect Hotel Building**\n",
      "\t* Students will learn about the importance of insects in ecosystems and how we can support them (50 minutes).\n",
      "\t* Design and build insect hotels using natural materials, exploring materials science and engineering concepts.\n",
      "5. **Lunch break** (30 minutes)\n",
      "\n",
      "**Coffee Break with Guest Speakers**\n",
      "\n",
      "6. **Ask a Scientist** (20 minutes)\n",
      "\t* Invite experts or former students to share their passions and experiences in various scientific fields (e.g., physics, biology, chemistry).\n",
      "\t* Encourage questions and discussions.\n",
      "\n",
      "7. **Chemistry Challenge 2: Homemade Lava Lamp**\n",
      "\t* Kids will learn about density, buoyancy, and chemical reactions by creating a homemade lava lamp using vegetable oil, water, food coloring, and Alka-Seltzer tablets (50 minutes).\n",
      "\n",
      "**Break**\n",
      "\n",
      "8. **Earth Science Exploration: Nature Scavenger Hunt** (40 minutes)\n",
      "\t* Students will go on an outdoor or indoor scavenger hunt to explore local ecosystems, identifying plants, animals, and geological formations.\n",
      "\n",
      "9. **Dinner**\n",
      "\n",
      "**Sunday:**\n",
      "\n",
      "1. **Physics Challenge 3: Marble Run Design**\n",
      "\t* Kids will learn about potential energy, gravity, and motion by designing their own marble run using cardboard, tape, and other materials (50 minutes).\n",
      "2. **Chemistry Challenge 4: Crystal Garden**\n",
      "\t* Students will learn about solubility, evaporation, and crystal formation by creating their own crystal gardens using super-saturated solutions and string (40 minutes).\n",
      "\n",
      "**Lunch break** (30 minutes)\n",
      "\n",
      "11.\n",
      "\n",
      "**Closing Session:**\n",
      "\n",
      "1. **Review and Evaluation** (20 minutes)\n",
      "\t* Review the scientific concepts covered during the weekend.\n",
      "2. **Goodbyes and Departure**\n",
      "\t* Express gratitude for participating, and encourage ongoing curiosity about science.\n",
      "\n",
      "**Pre-Workshop Preparation:**\n",
      "\n",
      "1. Provide necessary materials and equipment in advance (slime ingredients, insect hotel materials, etc.).\n",
      "2. Prepare a detailed schedule with contingency plans.\n",
      "3. Ensure teacher-chaperone ratio and adequate adult supervision throughout the workshop.\n",
      "\n",
      "To make this plan more engaging and interactive:\n",
      "\n",
      "* Add hands-on activities and experiments with visual aids to enhance understanding.\n",
      "* Encourage participation and team work in each challenge.\n",
      "* Incorporate local experts or guest speakers to add diversity and excitement.\n",
      "* Provide opportunities for students to ask questions, share their creations, and showcase their projects.\n",
      "* Make sure the schedule allows for breaks and relaxation time, allowing students to recharge throughout the weekend.\n",
      "\n",
      "By providing a comprehensive and engaging agenda, you'll create an unforgettable experience for your students, encouraging them to explore the wonders of science and fostering a lifelong love of learning!\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "def propose_thoughts(question, state, k=2):\n",
    "    # Propose up to k next “thoughts” that extend the current partial solution/state.\n",
    "    # Steps: build a short prompt with problem + current state; call your client with n=k. Then return a list of stripped strings (≤ k).\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~8-10 lines)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for _ in range(k):\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": question + \"\\n\" + state}],\n",
    "            temperature=1.0,\n",
    "        )\n",
    "        results.append(response.choices[0].message.content.strip())\n",
    "    return results\n",
    "\n",
    "\n",
    "def score_state(question, state):\n",
    "    # Score how promising a partial solution is on a 1–10 scale (higher is better).\n",
    "    # Steps: build a rating prompt; call the model; parse the first integer 1–10;\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~8-10 lines)\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that scores the quality of a partial solution to a problem on a scale of 1 to 10.  Only return the score, no other text.  Here's the problem and the current state:\"},\n",
    "            {\"role\": \"user\", \"content\": question + \"\\n\" + state},\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    print(\"--------------------------------\")\n",
    "    print(result)\n",
    "    print(\"--------------------------------\")\n",
    "    return int(result)\n",
    "\n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    # Run a tiny ToT search: expand states with propose_thoughts, score with score_state, keep top-k at each depth.\n",
    "    # Steps: initialize frontier=[(\"\", 0)]; for each depth, expand each state with k=width thoughts; score each; sort by score desc; keep top 'width'; return best state and score.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~12-16 lines)\n",
    "    \"\"\"\n",
    "    old_frontier = [(\"\", 0)]\n",
    "    for _ in range(depth):\n",
    "        new_frontier = []\n",
    "        for thought_node, score in old_frontier:\n",
    "            new_thought_nodes = propose_thoughts(question, thought_node, width)\n",
    "            new_frontier.extend([(new_thought_node, score_state(question, new_thought_node)) for new_thought_node in new_thought_nodes])\n",
    "        old_frontier = sorted(new_frontier, key=lambda x: x[1], reverse=True)[:width]\n",
    "    return old_frontier[0]\n",
    "\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question)\n",
    "\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasoins and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    # Use DDGS to run a simple web search and return joined snippets.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (~6 lines of code)\n",
    "    \"\"\"\n",
    "    results = DDGS().text(query, max_results=k)\n",
    "    return \"\\n\".join([result['title'] + \"\\n\" + result['href'] + \"\\n\" + result['body'] for result in results])\n",
    "\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/rz21fv5s5fn_4nv27jvlbh3m0000gn/T/ipykernel_73452/1378146609.py:11: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=MODEL, temperature=0)\n",
      "/var/folders/v4/rz21fv5s5fn_4nv27jvlbh3m0000gn/T/ipykernel_73452/1378146609.py:19: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, let's break down the best resources to learn Machine Learning (ML) in a way that anticipates its evolution towards 2025. The core concepts will remain relevant, but tools and applications are constantly evolving.\n",
      "\n",
      "The \"best\" resource depends heavily on your starting point (beginner, intermediate, advanced), background knowledge, learning style (visual, hands-on, theoretical), and goals. Here's a categorized overview focusing on foundational skills that will be essential in 2025:\n",
      "\n",
      "## I. Foundational Concepts & Python Programming\n",
      "\n",
      "1.  **Python Mastery:** ML heavily relies on Python libraries.\n",
      "    *   **Resource:** \"Python for Data Analysis\" by Wes McKinney (book), official NumPy/ Pandas/ Scikit-learn documentation, interactive platforms like Google's Numerical Methods in Finance and Economics Specialization (uses SciPy) or introductory courses focusing specifically on data manipulation with these tools. Understanding Python basics, control flow, functions, classes, and modules is crucial.\n",
      "2.  **Mathematics & Statistics:** The bedrock of ML algorithms.\n",
      "    *   **Resource:**\n",
      "        *   **Introductory Books:** \"Pattern Recognition and Machine Learning\" by Christopher Bishop (more comprehensive), or online resources like Khan Academy for statistics basics if needed.\n",
      "        *   **Online Courses:** StatQuest with Josh Starne on YouTube/ Udemy, Coursera's specialization in Regression Models for Prediction (statistics-focused) OR Andrew Ng's ML course covers necessary math (linear algebra, calculus, probability).\n",
      "        *   **Focus:** Understand linear algebra (vectors, matrices), multivariable calculus (gradients), probability distributions, and core statistical concepts like bias/variance tradeoff.\n",
      "\n",
      "## II. Core Machine Learning Algorithms\n",
      "\n",
      "1.  **Introductory Courses (Beginner-Friendly):**\n",
      "    *   **Coursera:**\n",
      "        *   Andrew Ng's \"Machine Learning\" course.\n",
      "        *   Stanford CS229 (\"Machine Learning\") lectures by Prof. Andrew Ng or others, available for free on YouTube but often mirrored on Coursera with assignments.\n",
      "        *   Google's ML fundamentals specialization (e.g., Machine Learning Crash Course).\n",
      "    *   **Fast.ai:** \"Practical Deep Learning\" course is known for its top-down approach starting from image recognition and building understanding bottom-up. Very hands-on and popular.\n",
      "    *   **edX:** Various courses, including those from MIT or other universities.\n",
      "\n",
      "2.  **Comprehensive Textbooks:**\n",
      "    *   **Resource:** Bishop's \"Pattern Recognition...\" (more theoretical), Hastie et al.'s \"The Elements of Statistical Learning\" (classic but dense). For a more applied approach, sometimes specific chapters in books like \"Deep Learning\" by Goodfellow et al. are used.\n",
      "\n",
      "3.  **Advanced Algorithm Exploration:**\n",
      "    *   **Resource:** Deep learning platforms like fast.ai or courses from Udacity/ Coursera that delve into neural networks and deep learning (e.g., Andrew Ng's DeepLearning.AI specialization). These will be even more critical as models get larger in 2025.\n",
      "\n",
      "## III. Practical Implementation & Libraries\n",
      "\n",
      "1.  **Scikit-learn:** The go-to library for traditional ML algorithms.\n",
      "    *   **Resource:** Official Scikit-learn documentation (essential reference) and tutorials accompanying courses like Andrew Ng's or Google's.\n",
      "2.  **Deep Learning Frameworks:**\n",
      "    *   **TensorFlow / Keras:** Widely used, especially in industry and research with TensorFlow Lite for edge deployment and TensorFlow.js for web ML becoming more relevant.\n",
      "        *   **Resource:** Official TensorFlow guides/ tutorials (including Keras integration), Google's ML courses. The focus should be on understanding the high-level API (Keras) first.\n",
      "    *   **PyTorch:** Extremely popular in academia and industry, known for flexibility and dynamic computation graphs.\n",
      "        *   **Resource:** PyTorch Tutorials on their website, fast.ai course resources.\n",
      "\n",
      "## IV. Data Handling & Feature Engineering\n",
      "\n",
      "1.  **Data Manipulation:**\n",
      "    *   **Pandas:** Essential library for handling tabular data.\n",
      "        *   **Resource:** Wes McKinney's \"Python for Data Analysis\" book, official Pandas documentation tutorials.\n",
      "2.  **Feature Engineering / Selection:**\n",
      "    *   **Scikit-learn Feature Engineering section:** Covers techniques like Imputer, Binarizer, StandardScaler, and feature selection methods.\n",
      "    *   **Online Tutorials/ Courses:** Often include sections on preprocessing and feature engineering.\n",
      "\n",
      "## V. Deep Learning Specialization\n",
      "\n",
      "1.  **Deep learning platforms (Fast.ai):** Highly recommended for a practical start to deep learning.\n",
      "2.  **Courses:**\n",
      "    *   Andrew Ng's DeepLearning.AI specialization (Coursera).\n",
      "    *   Stanford CS231n (\"Convolutional Neural Networks\") course resources (YouTube lectures, assignments). This will remain relevant as CNNs are fundamental in vision tasks for 2025.\n",
      "3.  **Books:**\n",
      "    *   Goodfellow et al.'s \"Deep Learning\" (more theoretical).\n",
      "4.  **Advanced Tutorials/ Blogs:**\n",
      "    *   Distill publications offer excellent, clear explanations of deep learning concepts.\n",
      "    *   Towards Data Science on Medium often features cutting-edge deep learning applications and tutorials.\n",
      "\n",
      "## VI. MLOps & Deployment\n",
      "\n",
      "This is becoming increasingly crucial as models move from research to production in 2025.\n",
      "*   **Resource:** Look for courses or resources specifically focused on ML Ops, deployment pipelines (e.g., using Docker), model monitoring, scaling ML systems, cloud platforms (AWS SageMaker, Azure ML, GCP Vertex AI) tutorials and documentation. Fast.ai touches on some aspects.\n",
      "\n",
      "## VII. Ethics & Responsible AI\n",
      "\n",
      "This is gaining significant importance.\n",
      "*   **Resource:** Look for courses or articles specifically addressing bias in algorithms, fairness metrics, explainability techniques (e.g., SHAP), privacy-preserving machine learning. Many ML courses now include ethical considerations sections.\n",
      "\n",
      "## VIII. Hands-on Practice Platforms\n",
      "\n",
      "1.  **Kaggle:** Excellent platform for datasets, competitions, and notebooks. Great way to practice with real-world data and see how others implement models.\n",
      "2.  **Google Colab / Binder:** Free Jupyter notebook environments often used with fast.ai or other courses.\n",
      "\n",
      "## IX. Communities & Staying Updated\n",
      "\n",
      "1.  **Kaggle Forums / Reddit (r/MachineLearning, r/MLOPs):** Engage with the community for questions and discussions.\n",
      "2.  **GitHub:** Explore open-source ML projects to see code in action.\n",
      "3.  **YouTube Channels:** Google's ML channel, StatQuest, Sentex, Lazy Programmer etc.\n",
      "4.  **Blogs / Newsletters:** Towards Data Science, Kaggle Blog, official blogs of framework creators (TensorFlow, PyTorch), arXiv preprints for the latest research.\n",
      "\n",
      "## Key Considerations for Learning in 2025\n",
      "\n",
      "*   **Focus on Fundamentals:** The core algorithms and concepts will remain unchanged. A deep understanding is more valuable than superficial knowledge of every new technique.\n",
      "*   **Python Proficiency:** Python remains dominant, especially with libraries like Scikit-learn evolving rapidly alongside TensorFlow/PyTorch.\n",
      "*   **Practical Application:** Build projects! Apply ML to problems you care about (using datasets from Kaggle or elsewhere). This solidifies understanding and builds portfolio pieces relevant for 2025 roles.\n",
      "*   **Ethical Awareness:** Learn how to build models that are fair, explainable, and respect privacy. This is becoming a critical skillset.\n",
      "\n",
      "Start with one of the beginner courses (like Andrew Ng's), get comfortable with Python basics and Scikit-learn fundamentals, then move into deep learning or explore specific areas like NLP or Computer Vision using dedicated resources. Supplement your learning heavily with hands-on practice on platforms like Kaggle.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the best resources to learn machine learning in 2025?',\n",
       " 'output': '\\nOkay, let\\'s break down the best resources to learn Machine Learning (ML) in a way that anticipates its evolution towards 2025. The core concepts will remain relevant, but tools and applications are constantly evolving.\\n\\nThe \"best\" resource depends heavily on your starting point (beginner, intermediate, advanced), background knowledge, learning style (visual, hands-on, theoretical), and goals. Here\\'s a categorized overview focusing on foundational skills that will be essential in 2025:\\n\\n## I. Foundational Concepts & Python Programming\\n\\n1.  **Python Mastery:** ML heavily relies on Python libraries.\\n    *   **Resource:** \"Python for Data Analysis\" by Wes McKinney (book), official NumPy/ Pandas/ Scikit-learn documentation, interactive platforms like Google\\'s Numerical Methods in Finance and Economics Specialization (uses SciPy) or introductory courses focusing specifically on data manipulation with these tools. Understanding Python basics, control flow, functions, classes, and modules is crucial.\\n2.  **Mathematics & Statistics:** The bedrock of ML algorithms.\\n    *   **Resource:**\\n        *   **Introductory Books:** \"Pattern Recognition and Machine Learning\" by Christopher Bishop (more comprehensive), or online resources like Khan Academy for statistics basics if needed.\\n        *   **Online Courses:** StatQuest with Josh Starne on YouTube/ Udemy, Coursera\\'s specialization in Regression Models for Prediction (statistics-focused) OR Andrew Ng\\'s ML course covers necessary math (linear algebra, calculus, probability).\\n        *   **Focus:** Understand linear algebra (vectors, matrices), multivariable calculus (gradients), probability distributions, and core statistical concepts like bias/variance tradeoff.\\n\\n## II. Core Machine Learning Algorithms\\n\\n1.  **Introductory Courses (Beginner-Friendly):**\\n    *   **Coursera:**\\n        *   Andrew Ng\\'s \"Machine Learning\" course.\\n        *   Stanford CS229 (\"Machine Learning\") lectures by Prof. Andrew Ng or others, available for free on YouTube but often mirrored on Coursera with assignments.\\n        *   Google\\'s ML fundamentals specialization (e.g., Machine Learning Crash Course).\\n    *   **Fast.ai:** \"Practical Deep Learning\" course is known for its top-down approach starting from image recognition and building understanding bottom-up. Very hands-on and popular.\\n    *   **edX:** Various courses, including those from MIT or other universities.\\n\\n2.  **Comprehensive Textbooks:**\\n    *   **Resource:** Bishop\\'s \"Pattern Recognition...\" (more theoretical), Hastie et al.\\'s \"The Elements of Statistical Learning\" (classic but dense). For a more applied approach, sometimes specific chapters in books like \"Deep Learning\" by Goodfellow et al. are used.\\n\\n3.  **Advanced Algorithm Exploration:**\\n    *   **Resource:** Deep learning platforms like fast.ai or courses from Udacity/ Coursera that delve into neural networks and deep learning (e.g., Andrew Ng\\'s DeepLearning.AI specialization). These will be even more critical as models get larger in 2025.\\n\\n## III. Practical Implementation & Libraries\\n\\n1.  **Scikit-learn:** The go-to library for traditional ML algorithms.\\n    *   **Resource:** Official Scikit-learn documentation (essential reference) and tutorials accompanying courses like Andrew Ng\\'s or Google\\'s.\\n2.  **Deep Learning Frameworks:**\\n    *   **TensorFlow / Keras:** Widely used, especially in industry and research with TensorFlow Lite for edge deployment and TensorFlow.js for web ML becoming more relevant.\\n        *   **Resource:** Official TensorFlow guides/ tutorials (including Keras integration), Google\\'s ML courses. The focus should be on understanding the high-level API (Keras) first.\\n    *   **PyTorch:** Extremely popular in academia and industry, known for flexibility and dynamic computation graphs.\\n        *   **Resource:** PyTorch Tutorials on their website, fast.ai course resources.\\n\\n## IV. Data Handling & Feature Engineering\\n\\n1.  **Data Manipulation:**\\n    *   **Pandas:** Essential library for handling tabular data.\\n        *   **Resource:** Wes McKinney\\'s \"Python for Data Analysis\" book, official Pandas documentation tutorials.\\n2.  **Feature Engineering / Selection:**\\n    *   **Scikit-learn Feature Engineering section:** Covers techniques like Imputer, Binarizer, StandardScaler, and feature selection methods.\\n    *   **Online Tutorials/ Courses:** Often include sections on preprocessing and feature engineering.\\n\\n## V. Deep Learning Specialization\\n\\n1.  **Deep learning platforms (Fast.ai):** Highly recommended for a practical start to deep learning.\\n2.  **Courses:**\\n    *   Andrew Ng\\'s DeepLearning.AI specialization (Coursera).\\n    *   Stanford CS231n (\"Convolutional Neural Networks\") course resources (YouTube lectures, assignments). This will remain relevant as CNNs are fundamental in vision tasks for 2025.\\n3.  **Books:**\\n    *   Goodfellow et al.\\'s \"Deep Learning\" (more theoretical).\\n4.  **Advanced Tutorials/ Blogs:**\\n    *   Distill publications offer excellent, clear explanations of deep learning concepts.\\n    *   Towards Data Science on Medium often features cutting-edge deep learning applications and tutorials.\\n\\n## VI. MLOps & Deployment\\n\\nThis is becoming increasingly crucial as models move from research to production in 2025.\\n*   **Resource:** Look for courses or resources specifically focused on ML Ops, deployment pipelines (e.g., using Docker), model monitoring, scaling ML systems, cloud platforms (AWS SageMaker, Azure ML, GCP Vertex AI) tutorials and documentation. Fast.ai touches on some aspects.\\n\\n## VII. Ethics & Responsible AI\\n\\nThis is gaining significant importance.\\n*   **Resource:** Look for courses or articles specifically addressing bias in algorithms, fairness metrics, explainability techniques (e.g., SHAP), privacy-preserving machine learning. Many ML courses now include ethical considerations sections.\\n\\n## VIII. Hands-on Practice Platforms\\n\\n1.  **Kaggle:** Excellent platform for datasets, competitions, and notebooks. Great way to practice with real-world data and see how others implement models.\\n2.  **Google Colab / Binder:** Free Jupyter notebook environments often used with fast.ai or other courses.\\n\\n## IX. Communities & Staying Updated\\n\\n1.  **Kaggle Forums / Reddit (r/MachineLearning, r/MLOPs):** Engage with the community for questions and discussions.\\n2.  **GitHub:** Explore open-source ML projects to see code in action.\\n3.  **YouTube Channels:** Google\\'s ML channel, StatQuest, Sentex, Lazy Programmer etc.\\n4.  **Blogs / Newsletters:** Towards Data Science, Kaggle Blog, official blogs of framework creators (TensorFlow, PyTorch), arXiv preprints for the latest research.\\n\\n## Key Considerations for Learning in 2025\\n\\n*   **Focus on Fundamentals:** The core algorithms and concepts will remain unchanged. A deep understanding is more valuable than superficial knowledge of every new technique.\\n*   **Python Proficiency:** Python remains dominant, especially with libraries like Scikit-learn evolving rapidly alongside TensorFlow/PyTorch.\\n*   **Practical Application:** Build projects! Apply ML to problems you care about (using datasets from Kaggle or elsewhere). This solidifies understanding and builds portfolio pieces relevant for 2025 roles.\\n*   **Ethical Awareness:** Learn how to build models that are fair, explainable, and respect privacy. This is becoming a critical skillset.\\n\\nStart with one of the beginner courses (like Andrew Ng\\'s), get comfortable with Python basics and Scikit-learn fundamentals, then move into deep learning or explore specific areas like NLP or Computer Vision using dedicated resources. Supplement your learning heavily with hands-on practice on platforms like Kaggle.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "\"\"\"\n",
    "YOUR CODE HERE (1 line of code)\n",
    "\"\"\"\n",
    "llm = ChatOllama(model=MODEL, temperature=0)\n",
    "\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "\"\"\"\n",
    "YOUR CODE HERE (1 line of code)\n",
    "\"\"\"\n",
    "tools = [search_tool]\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "\"\"\"\n",
    "YOUR CODE HERE (2 lines of code)\n",
    "\"\"\"\n",
    "agent.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\n",
      "\n",
      "## I. Foundational Knowledge (Essential & Evergreen)\n",
      "\n",
      "1.  **Core Concepts Books:**\n",
      "    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\n",
      "    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\n",
      "    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\n",
      "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\n",
      "    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\n",
      "\n",
      "2.  **Introductory Courses & Specializations:**\n",
      "    *   **Coursera - Andrew Ng's ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\n",
      "    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CS186):** Covers fundamentals of AI/ML from leading institutions. Focuses on practical applications and ethical considerations.\n",
      "    *   ***Focus:*** These provide structured introductions with video lectures, quizzes, and assignments.\n",
      "\n",
      "## II. Practical Coding & ML Pipelines\n",
      "\n",
      "3.  **Python Programming for Data Science (Crucial):**\n",
      "    *   **Official Python Documentation:** The ultimate reference for the language itself.\n",
      "    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, and data manipulation – core skills needed for ML pipelines.\n",
      "    *   **Codecademy / DataCamp (Python & Libraries):** Offer interactive courses specifically for Python relevant to data science/ML. Platforms like these will likely continue offering updated tracks.\n",
      "\n",
      "4.  **Core ML/DL Libraries:**\n",
      "    *   **Scikit-learn:** The workhorse of traditional ML in Python. Understanding its API and common estimators/pipelines is vital.\n",
      "        *   *Resource:* `sklearn.org` documentation, official tutorials, specific courses on Coursera/DataCamp/YouTube channels (e.g., Sentdex).\n",
      "    *   **TensorFlow / Keras:** Dominant deep learning framework. TensorFlow has extensive documentation and guides (`tensorflow.org`). Keras itself is often used as a high-level API within TensorFlow.\n",
      "        *   *Resource:* `keras.io` documentation, official TensorFlow tutorials, courses on Udacity or Coursera (like DeepLearning.AI).\n",
      "    *   **PyTorch:** Increasingly dominant in research and gaining significant industry adoption. Excellent for deep learning flexibility (`pytorch.org` has great tutorials).\n",
      "\n",
      "5.  **Interactive Coding Platforms:**\n",
      "    *   **Kaggle Learn:** Interactive lessons covering specific ML concepts using Python.\n",
      "    *   **Google Colab / Gradient:** Jupyter notebooks environments with free GPU/TPU access, often linked to tutorials and courses.\n",
      "\n",
      "## III. Advanced & Future-Ready Areas\n",
      "\n",
      "6.  **Deep Learning Specializations:**\n",
      "    *   **Fast.ai - \"Practical Deep Learning\":** Focuses on applying deep learning directly, moving away from low-level theory initially before diving deeper.\n",
      "        *   *Resource:* `course.fast.ai` (online course), their Discord community for support.\n",
      "    *   **Specialized Tutorials/YouTube Channels:** Channels like 3Blue1Brown (for intuition) and others focusing on specific DL architectures or techniques will likely continue to be valuable resources.\n",
      "\n",
      "7.  **Foundation Models & LLMs:**\n",
      "    *   **DeepSeek / DeepSpeed / Hugging Face tutorials:** As these become more central, platforms offering tools and tutorials for working with large language models (LLMs) and other foundation models will be key.\n",
      "        *   *Resource:* `huggingface.co` tutorials, official documentation from providers like OpenAI, Anthropic, Meta, Google, Microsoft. Also specific courses on Udemy or Coursera covering prompt engineering, fine-tuning, etc.\n",
      "\n",
      "8.  **MLOps (Operations for ML):**\n",
      "    *   **Introductory Courses:** Look for courses starting to emerge around MLOps best practices, deployment strategies, monitoring, and scaling ML models.\n",
      "        *   *Resource:* Platforms like Vertex AI, Azure Machine Learning, SageMaker have tutorials on their respective MLOps features. Also dedicated blogs (ML Ops Blog) or YouTube channels.\n",
      "\n",
      "9.  **Ethics & Responsible AI:**\n",
      "    *   **Courses/Modules:** Increasingly important. Look for courses specifically addressing bias mitigation, fairness, accountability, transparency (FAT/FAccT), and ethical considerations in ML/AI.\n",
      "        *   *Resource:* Ethics modules within data science/ML certifications, dedicated Coursera/courses on platforms like Udemy.\n",
      "\n",
      "## IV. Communities & Staying Updated\n",
      "\n",
      "10. **Online Forums:**\n",
      "    *   **Stack Overflow:** For specific coding problems (will always be relevant).\n",
      "    *   **Reddit - r/MachineLearning / r/deeplearning:** Great for discussions, project sharing, and staying updated on trends.\n",
      "        *   *Resource:* Active community engagement.\n",
      "\n",
      "11. **GitHub:**\n",
      "    *   Explore open-source ML projects to see real-world implementations (scikit-learn-contrib, various deep learning repos).\n",
      "    *   Kaggle datasets can also be valuable resources for practice data.\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Python Dominance:** Python will likely remain the lingua franca of ML.\n",
      "*   **GPU Acceleration:** Libraries like PyTorch and TensorFlow will continue to leverage GPUs heavily. Familiarity with CUDA or using cloud GPU instances (Colab, AWS SageMaker, AzureML, GCP Vertex) is important.\n",
      "*   **Rapid Evolution in Specific Areas:** While core concepts stay, areas like Transformers for vision, reinforcement learning applications, generative models beyond text/image, and specific MLOps tools will evolve quickly. Be prepared to learn new libraries or techniques within these domains as they mature and gain adoption by 2025.\n",
      "*   **Ethical AI:** This is becoming a core competency, not just an add-on.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "A solid plan for learning ML in the lead-up to (and likely throughout) 2025 would involve:\n",
      "\n",
      "1.  Master Python fundamentals and libraries like NumPy, Pandas, Matplotlib/Seaborn.\n",
      "2.  Take Andrew Ng's Specialization or equivalent courses to grasp core statistical concepts and algorithms (linear regression, logistic regression, SVMs, KNN, decision trees, random forests).\n",
      "3.  Dive deep into Scikit-learn for practical implementation of traditional ML models.\n",
      "4.  Learn one major deep learning framework (PyTorch recommended due to its flexibility and growing adoption in research/industry). Start with fundamentals like CNNs and RNNs using TensorFlow/Keras or PyTorch tutorials.\n",
      "5.  Explore interactive platforms like Kaggle Learn, Codecademy/DataCamp for hands-on practice.\n",
      "6.  Stay updated through communities (Reddit, Stack Overflow) and follow key blogs/tutorials.\n",
      "\n",
      "Remember that the best resource is often consistent practice on diverse datasets!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\n",
      "\n",
      "## I. Foundational Knowledge (Essential & Evergreen)\n",
      "\n",
      "1.  **Core Concepts Books:**\n",
      "    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\n",
      "    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\n",
      "    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\n",
      "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\n",
      "    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\n",
      "\n",
      "2.  **Introductory Courses & Specializations:**\n",
      "    *   **Coursera - Andrew Ng's ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\n",
      "    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CSx):** Another strong introductory course covering fundamentals of AI/ML.\n",
      "    *   ***Focus:*** These provide structured introductions and are widely recognized.\n",
      "\n",
      "## II. Practical Coding & Pipeline Skills\n",
      "\n",
      "3.  **Python Programming for ML:**\n",
      "    *   **Official Python Documentation:** The absolute standard language for data science in 2025.\n",
      "    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, core libraries used extensively in ML pipelines.\n",
      "\n",
      "4.  **Core ML Libraries & APIs:**\n",
      "    *   **Scikit-Learn (sklearn):** The most mature and widely used library for traditional ML algorithms (classification, regression, clustering). Absolutely fundamental.\n",
      "    *   **TensorFlow:** Developed by Google, still a major player, especially in deep learning and production deployment. Expect continued evolution but core concepts remain.\n",
      "    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for research and rapid development, particularly with its dynamic graphing nature. Likely to be dominant or co-dominant in many areas by 2025.\n",
      "    *   **Hugging Face Transformers Library:** Essential resource if learning about Large Language Models (LLMs) is part of the goal.\n",
      "    *   **MLflow / Kubeflow Pipelines:** Platforms for managing ML lifecycles, including tracking experiments and deploying models. Crucial for understanding MLOps concepts.\n",
      "\n",
      "5.  **Online Courses & Tutorials:**\n",
      "    *   **Kaggle Learn:** Interactive courses covering specific topics (Pandas, NumPy, Matplotlib, Scikit-Learn, Deep Learning with PyTelling etc.). Great hands-on practice.\n",
      "    *   **Fast.ai:** Focuses on practical deep learning using modern best practices. Their approach is top-down, starting from the application level before diving into theory.\n",
      "    *   **TensorFlow Tutorials / PyTorch Tutorials (Official):** Comprehensive guides and code examples directly from the creators.\n",
      "    *   ***Focus:*** These provide hands-on coding experience with current tools.\n",
      "\n",
      "## III. Advanced & Future-Ready Areas\n",
      "\n",
      "6.  **Deep Learning Books:**\n",
      "    *   **\"Deep Learning with PyTorch and FastAI\" by Jeremy Howard, Sylvain Gugger:** Practical deep learning book that complements the fast.ai course.\n",
      "    *   **\"Neural Networks and Deep Learning\" by Michael Nielsen (Free Online):** Excellent free resource for understanding NN fundamentals interactively.\n",
      "\n",
      "7.  **Foundation Models & LLMs:**\n",
      "    *   **DeepSeek's own resources / blogs:** As an AI developed by DeepSeek, I can recommend looking at the official blog or documentation if available, as they often discuss cutting-edge advancements.\n",
      "    *   **Hugging Face Tutorials (Torch Hub):** Huge repository of tutorials for using Transformers models and other libraries. Essential for learning about LLMs/Vision Transformers.\n",
      "    *   **Fast.ai / Practical Deep Learning:** Covers modern techniques including transfer learning with large datasets, highly relevant to foundation model usage.\n",
      "\n",
      "8.  **MLOps Concepts:**\n",
      "    *   **Kubeflow (Open Source):** The standard way to run ML pipelines on Kubernetes clusters in the cloud or edge.\n",
      "    *   **MLflow (Apache Project):** Widely adopted for experiment tracking and model deployment/management.\n",
      "    *   ***Focus:*** Understanding how to deploy, monitor, manage, and scale ML models will be increasingly important.\n",
      "\n",
      "## IV. Community & Cutting Edge\n",
      "\n",
      "9.  **arXiv:** The primary source for preprints of machine learning papers (often released before formal publication). Great way to stay current on research.\n",
      "10. **GitHub Repositories:**\n",
      "    *   Search for repositories using `topic:MachineLearning` or specific libraries (`scikit-learn`, `pytorch`). Look for well-maintained, actively developed projects with good documentation and tutorials.\n",
      "    *   Examples include official repos (TensorFlow, PyTorch), popular open-source ML frameworks, and community-driven examples.\n",
      "\n",
      "## V. Platforms & Communities\n",
      "\n",
      "11. **Kaggle:**\n",
      "    *   **Notebooks:** Excellent platform for running code in a pre-configured environment, sharing experiments, and learning from others.\n",
      "    *   **Datasets:** Access to real-world datasets.\n",
      "    *   **Leaderboards:** Participate in competitions to apply concepts under pressure.\n",
      "12. **TensorFlow Hub / Hugging Face Model Hub:** Repositories of reusable ML models and components.\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Emphasis on Ethics & Responsible AI:** Expect more resources focusing explicitly on bias, fairness, privacy, and transparency in ML models.\n",
      "*   **Rise of AutoML Tools (e.g., Hugging Face Transformers Hub):** These will become even more sophisticated, but understanding the underlying principles remains vital. Resources teaching how to use these effectively responsibly are key.\n",
      "*   **Continued Dominance of Python:** Libraries like TensorFlow, PyTorch, Scikit-Learn, and JAX (for research) will remain central.\n",
      "*   **JAX for Research:** While not always necessary for beginners, libraries built on JAX (`flax`, `sonnet`, `Haiku`) are becoming standard in academic and cutting-edge research circles. Resources explaining JAX could be valuable.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "The \"best\" resources depend heavily on your starting point (beginner, intermediate, advanced) and goals (job readiness, deep understanding, specific application). A good strategy is likely:\n",
      "\n",
      "1.  Start with foundational concepts from books or introductory courses.\n",
      "2.  Get hands-on using Scikit-Learn tutorials within Kaggle or similar platforms.\n",
      "3.  Then move to deeper learning using TensorFlow/PyTorch resources.\n",
      "\n",
      "Remember that the field evolves rapidly, so supplementing these core resources with active participation in communities like Kaggle and staying updated through blogs (like DeepSeek's) will be crucial for success by 2025. Good luck!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\n",
      "\n",
      "## I. Foundational Knowledge (Essential & Evergreen)\n",
      "\n",
      "1.  **Core Concepts Books:**\n",
      "    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\n",
      "    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\n",
      "    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\n",
      "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\n",
      "    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\n",
      "\n",
      "2.  **Introductory Courses & Specializations:**\n",
      "    *   **Coursera - Andrew Ng's ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\n",
      "    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CSx):** Another strong introductory course covering fundamentals of AI/ML.\n",
      "    *   ***Focus:*** These provide structured introductions and are widely recognized.\n",
      "\n",
      "## II. Practical Coding & Pipeline Skills\n",
      "\n",
      "3.  **Python Programming for ML:**\n",
      "    *   **Official Python Documentation:** The absolute standard language for data science in 2025.\n",
      "    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, core libraries used extensively in ML pipelines.\n",
      "\n",
      "4.  **Core ML Libraries & APIs:**\n",
      "    *   **Scikit-Learn (sklearn):** The most mature and widely used library for traditional ML algorithms (classification, regression, clustering). Absolutely fundamental.\n",
      "    *   **TensorFlow:** Developed by Google, still a major player, especially in deep learning and production deployment. Expect continued evolution but core concepts remain.\n",
      "    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for research and rapid development, particularly with its dynamic graphing nature. Likely to be dominant or co-dominant in many areas by 2025.\n",
      "    *   **Hugging Face Transformers Library:** Essential resource if learning about Large Language Models (LLMs) is part of the goal.\n",
      "    *   **MLflow / Kubeflow Pipelines:** Platforms for managing ML lifecycles, including tracking experiments and deploying models. Crucial for understanding MLOps concepts.\n",
      "\n",
      "5.  **Online Courses & Tutorials:**\n",
      "    *   **Kaggle Learn:** Interactive courses covering specific topics (Pandas, NumPy, Matplotlib, Scikit-Learn, Deep Learning with PyTelling etc.). Great hands-on practice.\n",
      "    *   **Fast.ai:** Focuses on practical deep learning using modern best practices. Their approach is top-down, starting from the application level before diving into theory.\n",
      "    *   **TensorFlow Tutorials / PyTorch Tutorials (Official):** Comprehensive guides and code examples directly from the creators.\n",
      "    *   ***Focus:*** These provide hands-on coding experience with current tools.\n",
      "\n",
      "## III. Advanced & Future-Ready Areas\n",
      "\n",
      "6.  **Deep Learning Books:**\n",
      "    *   **\"Deep Learning with PyTorch and FastAI\" by Jeremy Howard, Sylvain Gugger:** Practical deep learning book that complements the fast.ai course.\n",
      "    *   **\"Neural Networks and Deep Learning\" by Michael Nielsen (Free Online):** Excellent free resource for understanding NN fundamentals interactively.\n",
      "\n",
      "7.  **Foundation Models & LLMs:**\n",
      "    *   **DeepSeek's own resources / blogs:** As an AI developed by DeepSeek, I can recommend looking at the official blog or documentation if available, as they often discuss cutting-edge advancements.\n",
      "    *   **Hugging Face Tutorials (Torch Hub):** Huge repository of tutorials for using Transformers models and other libraries. Essential for learning about LLMs/Vision Transformers.\n",
      "    *   **Fast.ai / Practical Deep Learning:** Covers modern techniques including transfer learning with large datasets, highly relevant to foundation model usage.\n",
      "\n",
      "8.  **MLOps Concepts:**\n",
      "    *   **Kubeflow (Open Source):** The standard way to run ML pipelines on Kubernetes clusters in the cloud or edge.\n",
      "    *   **MLflow (Apache Project):** Widely adopted for experiment tracking and model deployment/management.\n",
      "    *   ***Focus:*** Understanding how to deploy, monitor, manage, and scale ML models will be increasingly important.\n",
      "\n",
      "## IV. Community & Cutting Edge\n",
      "\n",
      "9.  **arXiv:** The primary source for preprints of machine learning papers (often released before formal publication). Great way to stay current on research.\n",
      "10. **GitHub Repositories:**\n",
      "    *   Search for repositories using `topic:MachineLearning` or specific libraries (`scikit-learn`, `pytorch`). Look for well-maintained, actively developed projects with good documentation and tutorials.\n",
      "    *   Examples include official repos (TensorFlow, PyTorch), popular open-source ML frameworks, and community-driven examples.\n",
      "\n",
      "## V. Platforms & Communities\n",
      "\n",
      "11. **Kaggle:**\n",
      "    *   **Notebooks:** Excellent platform for running code in a pre-configured environment, sharing experiments, and learning from others.\n",
      "    *   **Datasets:** Access to real-world datasets.\n",
      "    *   **Leaderboards:** Participate in competitions to apply concepts under pressure.\n",
      "12. **TensorFlow Hub / Hugging Face Model Hub:** Repositories of reusable ML models and components.\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Emphasis on Ethics & Responsible AI:** Expect more resources focusing explicitly on bias, fairness, privacy, and transparency in ML models.\n",
      "*   **Rise of AutoML Tools (e.g., Hugging Face Transformers Hub):** These will become even more sophisticated, but understanding the underlying principles remains vital. Resources teaching how to use these effectively responsibly are key.\n",
      "*   **Continued Dominance of Python:** Libraries like TensorFlow, PyTorch, Scikit-Learn, and JAX (for research) will remain central.\n",
      "*   **JAX for Research:** While not always necessary for beginners, libraries built on JAX (`flax`, `sonnet`, `Haiku`) are becoming standard in academic and cutting-edge research circles. Resources explaining JAX could be valuable.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "The \"best\" resources depend heavily on your starting point (beginner, intermediate, advanced) and goals (job readiness, deep understanding, specific application). A good strategy is likely:\n",
      "\n",
      "1.  Start with foundational concepts from books or introductory courses.\n",
      "2.  Get hands-on using Scikit-Learn tutorials within Kaggle or similar platforms.\n",
      "3.  Then move to deeper learning using TensorFlow/PyTorch resources.\n",
      "\n",
      "Remember that the field evolves rapidly, so supplementing these core resources with active participation in communities like Kaggle and staying updated through blogs (like DeepSeek's) will be crucial for success by 2025. Good luck!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[Run 1] {'input': 'What are the best resources to learn ML in 2025?', 'output': '\\nOkay, since we\\'re looking ahead to resources potentially relevant or emerging by 2025, it\\'s crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\\n\\n## I. Foundational Knowledge (Essential & Evergreen)\\n\\n1.  **Core Concepts Books:**\\n    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\\n    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\\n    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\\n    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\\n    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\\n\\n2.  **Introductory Courses & Specializations:**\\n    *   **Coursera - Andrew Ng\\'s ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\\n    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CSx):** Another strong introductory course covering fundamentals of AI/ML.\\n    *   ***Focus:*** These provide structured introductions and are widely recognized.\\n\\n## II. Practical Coding & Pipeline Skills\\n\\n3.  **Python Programming for ML:**\\n    *   **Official Python Documentation:** The absolute standard language for data science in 2025.\\n    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, core libraries used extensively in ML pipelines.\\n\\n4.  **Core ML Libraries & APIs:**\\n    *   **Scikit-Learn (sklearn):** The most mature and widely used library for traditional ML algorithms (classification, regression, clustering). Absolutely fundamental.\\n    *   **TensorFlow:** Developed by Google, still a major player, especially in deep learning and production deployment. Expect continued evolution but core concepts remain.\\n    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for research and rapid development, particularly with its dynamic graphing nature. Likely to be dominant or co-dominant in many areas by 2025.\\n    *   **Hugging Face Transformers Library:** Essential resource if learning about Large Language Models (LLMs) is part of the goal.\\n    *   **MLflow / Kubeflow Pipelines:** Platforms for managing ML lifecycles, including tracking experiments and deploying models. Crucial for understanding MLOps concepts.\\n\\n5.  **Online Courses & Tutorials:**\\n    *   **Kaggle Learn:** Interactive courses covering specific topics (Pandas, NumPy, Matplotlib, Scikit-Learn, Deep Learning with PyTelling etc.). Great hands-on practice.\\n    *   **Fast.ai:** Focuses on practical deep learning using modern best practices. Their approach is top-down, starting from the application level before diving into theory.\\n    *   **TensorFlow Tutorials / PyTorch Tutorials (Official):** Comprehensive guides and code examples directly from the creators.\\n    *   ***Focus:*** These provide hands-on coding experience with current tools.\\n\\n## III. Advanced & Future-Ready Areas\\n\\n6.  **Deep Learning Books:**\\n    *   **\"Deep Learning with PyTorch and FastAI\" by Jeremy Howard, Sylvain Gugger:** Practical deep learning book that complements the fast.ai course.\\n    *   **\"Neural Networks and Deep Learning\" by Michael Nielsen (Free Online):** Excellent free resource for understanding NN fundamentals interactively.\\n\\n7.  **Foundation Models & LLMs:**\\n    *   **DeepSeek\\'s own resources / blogs:** As an AI developed by DeepSeek, I can recommend looking at the official blog or documentation if available, as they often discuss cutting-edge advancements.\\n    *   **Hugging Face Tutorials (Torch Hub):** Huge repository of tutorials for using Transformers models and other libraries. Essential for learning about LLMs/Vision Transformers.\\n    *   **Fast.ai / Practical Deep Learning:** Covers modern techniques including transfer learning with large datasets, highly relevant to foundation model usage.\\n\\n8.  **MLOps Concepts:**\\n    *   **Kubeflow (Open Source):** The standard way to run ML pipelines on Kubernetes clusters in the cloud or edge.\\n    *   **MLflow (Apache Project):** Widely adopted for experiment tracking and model deployment/management.\\n    *   ***Focus:*** Understanding how to deploy, monitor, manage, and scale ML models will be increasingly important.\\n\\n## IV. Community & Cutting Edge\\n\\n9.  **arXiv:** The primary source for preprints of machine learning papers (often released before formal publication). Great way to stay current on research.\\n10. **GitHub Repositories:**\\n    *   Search for repositories using `topic:MachineLearning` or specific libraries (`scikit-learn`, `pytorch`). Look for well-maintained, actively developed projects with good documentation and tutorials.\\n    *   Examples include official repos (TensorFlow, PyTorch), popular open-source ML frameworks, and community-driven examples.\\n\\n## V. Platforms & Communities\\n\\n11. **Kaggle:**\\n    *   **Notebooks:** Excellent platform for running code in a pre-configured environment, sharing experiments, and learning from others.\\n    *   **Datasets:** Access to real-world datasets.\\n    *   **Leaderboards:** Participate in competitions to apply concepts under pressure.\\n12. **TensorFlow Hub / Hugging Face Model Hub:** Repositories of reusable ML models and components.\\n\\n## Key Considerations for 2025\\n\\n*   **Emphasis on Ethics & Responsible AI:** Expect more resources focusing explicitly on bias, fairness, privacy, and transparency in ML models.\\n*   **Rise of AutoML Tools (e.g., Hugging Face Transformers Hub):** These will become even more sophisticated, but understanding the underlying principles remains vital. Resources teaching how to use these effectively responsibly are key.\\n*   **Continued Dominance of Python:** Libraries like TensorFlow, PyTorch, Scikit-Learn, and JAX (for research) will remain central.\\n*   **JAX for Research:** While not always necessary for beginners, libraries built on JAX (`flax`, `sonnet`, `Haiku`) are becoming standard in academic and cutting-edge research circles. Resources explaining JAX could be valuable.\\n\\n## Recommendation\\n\\nThe \"best\" resources depend heavily on your starting point (beginner, intermediate, advanced) and goals (job readiness, deep understanding, specific application). A good strategy is likely:\\n\\n1.  Start with foundational concepts from books or introductory courses.\\n2.  Get hands-on using Scikit-Learn tutorials within Kaggle or similar platforms.\\n3.  Then move to deeper learning using TensorFlow/PyTorch resources.\\n\\nRemember that the field evolves rapidly, so supplementing these core resources with active participation in communities like Kaggle and staying updated through blogs (like DeepSeek\\'s) will be crucial for success by 2025. Good luck!'}…\n",
      "[Run 2] {'input': 'What are the best resources to learn ML in 2025?', 'output': '\\nOkay, since we\\'re looking ahead to resources potentially relevant or emerging by 2025, it\\'s crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\\n\\n## I. Foundational Knowledge (Essential & Evergreen)\\n\\n1.  **Core Concepts Books:**\\n    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\\n    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\\n    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\\n    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\\n    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\\n\\n2.  **Introductory Courses & Specializations:**\\n    *   **Coursera - Andrew Ng\\'s ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\\n    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CSx):** Another strong introductory course covering fundamentals of AI/ML.\\n    *   ***Focus:*** These provide structured introductions and are widely recognized.\\n\\n## II. Practical Coding & Pipeline Skills\\n\\n3.  **Python Programming for ML:**\\n    *   **Official Python Documentation:** The absolute standard language for data science in 2025.\\n    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, core libraries used extensively in ML pipelines.\\n\\n4.  **Core ML Libraries & APIs:**\\n    *   **Scikit-Learn (sklearn):** The most mature and widely used library for traditional ML algorithms (classification, regression, clustering). Absolutely fundamental.\\n    *   **TensorFlow:** Developed by Google, still a major player, especially in deep learning and production deployment. Expect continued evolution but core concepts remain.\\n    *   **PyTorch:** Developed by Facebook (Meta), extremely popular for research and rapid development, particularly with its dynamic graphing nature. Likely to be dominant or co-dominant in many areas by 2025.\\n    *   **Hugging Face Transformers Library:** Essential resource if learning about Large Language Models (LLMs) is part of the goal.\\n    *   **MLflow / Kubeflow Pipelines:** Platforms for managing ML lifecycles, including tracking experiments and deploying models. Crucial for understanding MLOps concepts.\\n\\n5.  **Online Courses & Tutorials:**\\n    *   **Kaggle Learn:** Interactive courses covering specific topics (Pandas, NumPy, Matplotlib, Scikit-Learn, Deep Learning with PyTelling etc.). Great hands-on practice.\\n    *   **Fast.ai:** Focuses on practical deep learning using modern best practices. Their approach is top-down, starting from the application level before diving into theory.\\n    *   **TensorFlow Tutorials / PyTorch Tutorials (Official):** Comprehensive guides and code examples directly from the creators.\\n    *   ***Focus:*** These provide hands-on coding experience with current tools.\\n\\n## III. Advanced & Future-Ready Areas\\n\\n6.  **Deep Learning Books:**\\n    *   **\"Deep Learning with PyTorch and FastAI\" by Jeremy Howard, Sylvain Gugger:** Practical deep learning book that complements the fast.ai course.\\n    *   **\"Neural Networks and Deep Learning\" by Michael Nielsen (Free Online):** Excellent free resource for understanding NN fundamentals interactively.\\n\\n7.  **Foundation Models & LLMs:**\\n    *   **DeepSeek\\'s own resources / blogs:** As an AI developed by DeepSeek, I can recommend looking at the official blog or documentation if available, as they often discuss cutting-edge advancements.\\n    *   **Hugging Face Tutorials (Torch Hub):** Huge repository of tutorials for using Transformers models and other libraries. Essential for learning about LLMs/Vision Transformers.\\n    *   **Fast.ai / Practical Deep Learning:** Covers modern techniques including transfer learning with large datasets, highly relevant to foundation model usage.\\n\\n8.  **MLOps Concepts:**\\n    *   **Kubeflow (Open Source):** The standard way to run ML pipelines on Kubernetes clusters in the cloud or edge.\\n    *   **MLflow (Apache Project):** Widely adopted for experiment tracking and model deployment/management.\\n    *   ***Focus:*** Understanding how to deploy, monitor, manage, and scale ML models will be increasingly important.\\n\\n## IV. Community & Cutting Edge\\n\\n9.  **arXiv:** The primary source for preprints of machine learning papers (often released before formal publication). Great way to stay current on research.\\n10. **GitHub Repositories:**\\n    *   Search for repositories using `topic:MachineLearning` or specific libraries (`scikit-learn`, `pytorch`). Look for well-maintained, actively developed projects with good documentation and tutorials.\\n    *   Examples include official repos (TensorFlow, PyTorch), popular open-source ML frameworks, and community-driven examples.\\n\\n## V. Platforms & Communities\\n\\n11. **Kaggle:**\\n    *   **Notebooks:** Excellent platform for running code in a pre-configured environment, sharing experiments, and learning from others.\\n    *   **Datasets:** Access to real-world datasets.\\n    *   **Leaderboards:** Participate in competitions to apply concepts under pressure.\\n12. **TensorFlow Hub / Hugging Face Model Hub:** Repositories of reusable ML models and components.\\n\\n## Key Considerations for 2025\\n\\n*   **Emphasis on Ethics & Responsible AI:** Expect more resources focusing explicitly on bias, fairness, privacy, and transparency in ML models.\\n*   **Rise of AutoML Tools (e.g., Hugging Face Transformers Hub):** These will become even more sophisticated, but understanding the underlying principles remains vital. Resources teaching how to use these effectively responsibly are key.\\n*   **Continued Dominance of Python:** Libraries like TensorFlow, PyTorch, Scikit-Learn, and JAX (for research) will remain central.\\n*   **JAX for Research:** While not always necessary for beginners, libraries built on JAX (`flax`, `sonnet`, `Haiku`) are becoming standard in academic and cutting-edge research circles. Resources explaining JAX could be valuable.\\n\\n## Recommendation\\n\\nThe \"best\" resources depend heavily on your starting point (beginner, intermediate, advanced) and goals (job readiness, deep understanding, specific application). A good strategy is likely:\\n\\n1.  Start with foundational concepts from books or introductory courses.\\n2.  Get hands-on using Scikit-Learn tutorials within Kaggle or similar platforms.\\n3.  Then move to deeper learning using TensorFlow/PyTorch resources.\\n\\nRemember that the field evolves rapidly, so supplementing these core resources with active participation in communities like Kaggle and staying updated through blogs (like DeepSeek\\'s) will be crucial for success by 2025. Good luck!'}…\n",
      "[Run 3] {'input': 'What are the best resources to learn ML in 2025?', 'output': '\\nOkay, since we\\'re looking ahead to resources potentially relevant or emerging by 2025, it\\'s crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidly evolving areas like foundation models (large language models, vision transformers etc.) and MLOps. Here’s a breakdown of likely best resources:\\n\\n## I. Foundational Knowledge (Essential & Evergreen)\\n\\n1.  **Core Concepts Books:**\\n    *   **\"Pattern Recognition and Machine Learning\" by Christopher Bishop:** A comprehensive textbook covering the fundamentals.\\n    *   **\"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman et al.:** The bible for statistical learning theory (available online free). Focuses on understanding principles.\\n    *   **\"Deep Learning\" by Goodfellow, Bengio, and Courville:** The definitive deep learning book. Requires strong math background but is incredibly thorough.\\n    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron:** Excellent for understanding core algorithms implemented in popular Python libraries (covers up to relevant versions).\\n    *   ***Focus:*** These books provide the theoretical underpinnings that remain relatively stable over time.\\n\\n2.  **Introductory Courses & Specializations:**\\n    *   **Coursera - Andrew Ng\\'s ML and AI Specialization:** Still highly relevant in 2025 for understanding core concepts, linear regression, logistic regression, neural networks, etc., presented clearly.\\n    *   **edX - MIT / Microsoft Introduction to Artificial Intelligence (CS186):** Covers fundamentals of AI/ML from leading institutions. Focuses on practical applications and ethical considerations.\\n    *   ***Focus:*** These provide structured introductions with video lectures, quizzes, and assignments.\\n\\n## II. Practical Coding & ML Pipelines\\n\\n3.  **Python Programming for Data Science (Crucial):**\\n    *   **Official Python Documentation:** The ultimate reference for the language itself.\\n    *   **\"Python for Data Analysis\" by Wes McKinney:** Focuses on Pandas, NumPy, and data manipulation – core skills needed for ML pipelines.\\n    *   **Codecademy / DataCamp (Python & Libraries):** Offer interactive courses specifically for Python relevant to data science/ML. Platforms like these will likely continue offering updated tracks.\\n\\n4.  **Core ML/DL Libraries:**\\n    *   **Scikit-learn:** The workhorse of traditional ML in Python. Understanding its API and common estimators/pipelines is vital.\\n        *   *Resource:* `sklearn.org` documentation, official tutorials, specific courses on Coursera/DataCamp/YouTube channels (e.g., Sentdex).\\n    *   **TensorFlow / Keras:** Dominant deep learning framework. TensorFlow has extensive documentation and guides (`tensorflow.org`). Keras itself is often used as a high-level API within TensorFlow.\\n        *   *Resource:* `keras.io` documentation, official TensorFlow tutorials, courses on Udacity or Coursera (like DeepLearning.AI).\\n    *   **PyTorch:** Increasingly dominant in research and gaining significant industry adoption. Excellent for deep learning flexibility (`pytorch.org` has great tutorials).\\n\\n5.  **Interactive Coding Platforms:**\\n    *   **Kaggle Learn:** Interactive lessons covering specific ML concepts using Python.\\n    *   **Google Colab / Gradient:** Jupyter notebooks environments with free GPU/TPU access, often linked to tutorials and courses.\\n\\n## III. Advanced & Future-Ready Areas\\n\\n6.  **Deep Learning Specializations:**\\n    *   **Fast.ai - \"Practical Deep Learning\":** Focuses on applying deep learning directly, moving away from low-level theory initially before diving deeper.\\n        *   *Resource:* `course.fast.ai` (online course), their Discord community for support.\\n    *   **Specialized Tutorials/YouTube Channels:** Channels like 3Blue1Brown (for intuition) and others focusing on specific DL architectures or techniques will likely continue to be valuable resources.\\n\\n7.  **Foundation Models & LLMs:**\\n    *   **DeepSeek / DeepSpeed / Hugging Face tutorials:** As these become more central, platforms offering tools and tutorials for working with large language models (LLMs) and other foundation models will be key.\\n        *   *Resource:* `huggingface.co` tutorials, official documentation from providers like OpenAI, Anthropic, Meta, Google, Microsoft. Also specific courses on Udemy or Coursera covering prompt engineering, fine-tuning, etc.\\n\\n8.  **MLOps (Operations for ML):**\\n    *   **Introductory Courses:** Look for courses starting to emerge around MLOps best practices, deployment strategies, monitoring, and scaling ML models.\\n        *   *Resource:* Platforms like Vertex AI, Azure Machine Learning, SageMaker have tutorials on their respective MLOps features. Also dedicated blogs (ML Ops Blog) or YouTube channels.\\n\\n9.  **Ethics & Responsible AI:**\\n    *   **Courses/Modules:** Increasingly important. Look for courses specifically addressing bias mitigation, fairness, accountability, transparency (FAT/FAccT), and ethical considerations in ML/AI.\\n        *   *Resource:* Ethics modules within data science/ML certifications, dedicated Coursera/courses on platforms like Udemy.\\n\\n## IV. Communities & Staying Updated\\n\\n10. **Online Forums:**\\n    *   **Stack Overflow:** For specific coding problems (will always be relevant).\\n    *   **Reddit - r/MachineLearning / r/deeplearning:** Great for discussions, project sharing, and staying updated on trends.\\n        *   *Resource:* Active community engagement.\\n\\n11. **GitHub:**\\n    *   Explore open-source ML projects to see real-world implementations (scikit-learn-contrib, various deep learning repos).\\n    *   Kaggle datasets can also be valuable resources for practice data.\\n\\n## Key Considerations for 2025\\n\\n*   **Python Dominance:** Python will likely remain the lingua franca of ML.\\n*   **GPU Acceleration:** Libraries like PyTorch and TensorFlow will continue to leverage GPUs heavily. Familiarity with CUDA or using cloud GPU instances (Colab, AWS SageMaker, AzureML, GCP Vertex) is important.\\n*   **Rapid Evolution in Specific Areas:** While core concepts stay, areas like Transformers for vision, reinforcement learning applications, generative models beyond text/image, and specific MLOps tools will evolve quickly. Be prepared to learn new libraries or techniques within these domains as they mature and gain adoption by 2025.\\n*   **Ethical AI:** This is becoming a core competency, not just an add-on.\\n\\n## Recommendation\\n\\nA solid plan for learning ML in the lead-up to (and likely throughout) 2025 would involve:\\n\\n1.  Master Python fundamentals and libraries like NumPy, Pandas, Matplotlib/Seaborn.\\n2.  Take Andrew Ng\\'s Specialization or equivalent courses to grasp core statistical concepts and algorithms (linear regression, logistic regression, SVMs, KNN, decision trees, random forests).\\n3.  Dive deep into Scikit-learn for practical implementation of traditional ML models.\\n4.  Learn one major deep learning framework (PyTorch recommended due to its flexibility and growing adoption in research/industry). Start with fundamentals like CNNs and RNNs using TensorFlow/Keras or PyTorch tutorials.\\n5.  Explore interactive platforms like Kaggle Learn, Codecademy/DataCamp for hands-on practice.\\n6.  Stay updated through communities (Reddit, Stack Overflow) and follow key blogs/tutorials.\\n\\nRemember that the best resource is often consistent practice on diverse datasets!'}…\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=n) as executor:\n",
    "        futures = [executor.submit(agent.invoke, query) for _ in range(n)]\n",
    "        answers = [future.result() for future in futures]\n",
    "    return answers\n",
    "\n",
    "answers = parallel_research(\"What are the best resources to learn ML in 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7426f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run 1] \n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidl…\n",
      "[Run 2] \n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidl…\n",
      "[Run 3] \n",
      "Okay, since we're looking ahead to resources potentially relevant or emerging by 2025, it's crucial to focus on foundational concepts and platforms with longevity, while also keeping an eye on rapidl…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,a in enumerate(answers,1):\n",
    "    print(f\"[Run {i}] {a['output'][:200]}…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "deep_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
